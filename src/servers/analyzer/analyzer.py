# servers/analyzer/analyzer.py
import json
import os
import logging
import numpy as np
from typing import Dict, Any, Optional, List
from openai import OpenAI
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Analyzer:
    def __init__(self, 
                 openai_api_key: Optional[str] = None,
                 openai_base_url: Optional[str] = None,
                 default_model: str = "gpt-4"):
        """
        åˆå§‹åŒ–ç»¼åˆåˆ†æå™¨
        """
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.openai_base_url = openai_base_url or os.getenv("OPENAI_BASE_URL")
        self.default_model = default_model
        self.client = None
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if self.openai_api_key:
            try:
                self.client = OpenAI(
                    api_key=self.openai_api_key,
                    base_url=self.openai_base_url
                )
                logger.info("âœ… Analyzer AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ Analyzer AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        else:
            logger.warning("âš ï¸ æœªæä¾›OpenAI APIå¯†é’¥ï¼ŒAIåŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def analyze_user_query(self, user_query: str) -> Dict[str, Any]:
        """
        åˆ†æç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«è´§å¸å¯¹ã€é—®é¢˜ç±»å‹å’Œåˆ†æéœ€æ±‚
        """
        if not self.client:
            return {
                "success": False,
                "error": "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®",
                "analysis": None
            }
        
        try:
            prompt = f"""
è¯·åˆ†æä»¥ä¸‹å¤–æ±‡äº¤æ˜“ç›¸å…³çš„ç”¨æˆ·æŸ¥è¯¢ï¼š

ç”¨æˆ·æŸ¥è¯¢: "{user_query}"

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. è¯†åˆ«ç”¨æˆ·æåˆ°çš„å…·ä½“è´§å¸å¯¹ï¼ˆå¦‚EUR/USD, GBP/JPYç­‰ï¼‰
2. åˆ†æç”¨æˆ·çš„æ ¸å¿ƒé—®é¢˜å’Œå…³æ³¨ç‚¹
3. ç¡®å®šåˆ†æçš„é‡ç‚¹æ–¹å‘
4. æå‡ºéœ€è¦æ”¶é›†çš„æ•°æ®ç±»å‹
5. ç»™å‡ºåˆ†æå»ºè®®

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "identified_currency_pairs": ["è´§å¸å¯¹1", "è´§å¸å¯¹2"],
    "primary_currency_pair": "ä¸»è¦è´§å¸å¯¹",
    "query_type": "è¶‹åŠ¿åˆ†æ/æŠ€æœ¯åˆ†æ/åŸºæœ¬é¢åˆ†æ/é£é™©è¯„ä¼°/äº¤æ˜“æœºä¼šç­‰",
    "user_concerns": ["ç”¨æˆ·å…³æ³¨ç‚¹1", "ç”¨æˆ·å…³æ³¨ç‚¹2"],
    "analysis_focus": ["åˆ†æé‡ç‚¹1", "åˆ†æé‡ç‚¹2"],
    "required_data": ["å¸‚åœºæ•°æ®", "ç»æµæ•°æ®", "æŠ€æœ¯æŒ‡æ ‡", "æ–°é—»æƒ…ç»ªç­‰"],
    "analysis_suggestions": ["å»ºè®®1", "å»ºè®®2"],
    "complexity_level": "ç®€å•/ä¸­ç­‰/å¤æ‚"
}}
"""
            
            response = self.client.chat.completions.create(
                model=self.default_model,
                messages=[
                    {
                        "role": "system", 
                        "content": """æ‚¨æ˜¯ä¸“ä¸šçš„å¤–æ±‡å¸‚åœºåˆ†æå¸ˆï¼Œæ“…é•¿ç†è§£ç”¨æˆ·äº¤æ˜“ç›¸å…³é—®é¢˜å¹¶åˆ¶å®šåˆ†æè®¡åˆ’ã€‚
è¯·å‡†ç¡®è¯†åˆ«è´§å¸å¯¹ï¼Œç†è§£ç”¨æˆ·çœŸå®éœ€æ±‚ï¼Œå¹¶æä¾›ä¸“ä¸šçš„åˆ†æå»ºè®®ã€‚"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            query_analysis = json.loads(response.choices[0].message.content)
            
            return {
                "success": True,
                "query_analysis": query_analysis,
                "original_query": user_query,
                "timestamp": self._get_timestamp()
            }
            
        except Exception as e:
            logger.error(f"ç”¨æˆ·æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"æŸ¥è¯¢åˆ†æå¤±è´¥: {str(e)}",
                "analysis": None
            }
    
    def generate_comprehensive_analysis(self, 
                                    market_data: Dict[str, Any],
                                    economic_data: Dict[str, Any], 
                                    technical_data: Dict[str, Any],
                                    user_query: str = "",
                                    query_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæ˜“è¯»åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«æ·±åº¦äº¤æ˜“å»ºè®®
        """
        if not self.client:
            return {
                "success": False,
                "error": "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®",
                "analysis": None
            }
        
        try:
            # å¦‚æœæ²¡æœ‰æä¾›æŸ¥è¯¢åˆ†æï¼Œå…ˆè¿›è¡Œåˆ†æ
            if not query_analysis and user_query:
                query_result = self.analyze_user_query(user_query)
                if query_result["success"]:
                    query_analysis = query_result["query_analysis"]
            
            # æ™ºèƒ½æ•°æ®æå–å’Œåˆ†æ
            analysis_context = self._prepare_analysis_context(market_data, economic_data, technical_data, user_query, query_analysis)
            
            # æ„å»ºåŠ¨æ€åˆ†ææç¤º - å¢å¼ºäº¤æ˜“å»ºè®®éƒ¨åˆ†
            prompt = self._build_dynamic_analysis_prompt(analysis_context)
            
            # è°ƒç”¨AIåˆ†æ
            response = self.client.chat.completions.create(
                model=self.default_model,
                messages=[
                    {
                        "role": "system", 
                        "content": """æ‚¨æ˜¯é¡¶çº§å¤–æ±‡äº¤æ˜“åˆ†æå¸ˆï¼Œæ“…é•¿ç»¼åˆæŠ€æœ¯åˆ†æã€åŸºæœ¬é¢åˆ†æå’Œå¸‚åœºæƒ…ç»ªåˆ†æã€‚
è¯·æ ¹æ®å®é™…å¯ç”¨çš„æ•°æ®å†…å®¹ï¼Œæä¾›ä¸“ä¸šã€æ˜“è¯»ã€ç»“æ„æ¸…æ™°çš„åˆ†ææŠ¥å‘Šã€‚
é‡ç‚¹åˆ†æå®é™…å­˜åœ¨çš„æ•°æ®ï¼Œå¯¹äºç¼ºå¤±çš„æ•°æ®è¦æ˜ç¡®è¯´æ˜é™åˆ¶ã€‚
ç‰¹åˆ«è¦åŸºäºæ‰€æœ‰å¯ç”¨æŒ‡æ ‡ï¼ˆç»æµäº‹ä»¶ã€æŠ€æœ¯ä¿¡å·ã€ä»·æ ¼æ•°æ®ï¼‰ç»™å‡ºå…·ä½“çš„äº¤æ˜“å»ºè®®ã€‚
ä½¿ç”¨markdowné£æ ¼çš„æ ¼å¼ï¼ŒåŒ…å«å…·ä½“çš„ä»·æ ¼æ°´å¹³ã€æ•°æ®æ”¯æŒå’Œå¯æ‰§è¡Œçš„äº¤æ˜“ç­–ç•¥ã€‚"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3
            )
            
            analysis_text = response.choices[0].message.content
            
            return {
                "success": True,
                "analysis": analysis_text,
                "query_analysis": query_analysis,
                "data_context": analysis_context["data_availability"],
                "metadata": {
                    "model_used": self.default_model,
                    "user_query": user_query,
                    "data_sources_used": analysis_context["available_sources"],
                    "analysis_timestamp": self._get_timestamp(),
                    "output_format": "readable_text"
                }
            }
            
        except Exception as e:
            logger.error(f"ç»¼åˆåˆ†æç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"åˆ†æç”Ÿæˆå¤±è´¥: {str(e)}",
                "analysis": None
            }

    
    def _prepare_analysis_context(self, market_data, economic_data, technical_data, user_query, query_analysis):
        """å‡†å¤‡åˆ†æä¸Šä¸‹æ–‡ï¼Œè¯†åˆ«å¯ç”¨çš„æ•°æ®å†…å®¹å’Œé‡ç‚¹"""
        # æå–æ•°æ®
        market_info = self._extract_market_data(market_data)
        economic_info = self._extract_economic_data(economic_data)
        technical_info = self._extract_technical_data(technical_data)
        
        # åˆ†ææ•°æ®å¯ç”¨æ€§å’Œå†…å®¹ç‰¹ç‚¹
        context = {
            "user_query": user_query,
            "query_analysis": query_analysis,
            "market_data": market_info,
            "economic_data": economic_info,
            "technical_data": technical_info,
            "data_availability": self._analyze_data_availability(market_info, economic_info, technical_info),
            "analysis_focus": self._determine_analysis_focus(market_info, economic_info, technical_info, query_analysis),
            "available_sources": []
        }
        
        # ç¡®å®šå¯ç”¨æ•°æ®æº
        if context["data_availability"]["has_market_data"]:
            context["available_sources"].append("market")
        if context["data_availability"]["has_economic_data"]:
            context["available_sources"].append("economic")
        if context["data_availability"]["has_technical_data"]:
            context["available_sources"].append("technical")
            
        return context
    
    def _analyze_data_availability(self, market_info, economic_info, technical_info):
        """åˆ†ææ•°æ®å¯ç”¨æ€§"""
        return {
            "has_market_data": bool(market_info.get("price")),
            "has_economic_data": bool(economic_info.get("sentiment") or economic_info.get("events")),
            "has_technical_data": bool(technical_info.get("signals") or technical_info.get("indicators")),
            "market_data_type": market_info.get("metadata", {}).get("data_type"),
            "economic_data_type": "multi_currency" if economic_info.get("analysis_type") == "multi_currency" else "single_currency",
            "technical_data_type": technical_info.get("data_type")
        }
    
    def _determine_analysis_focus(self, market_info, economic_info, technical_info, query_analysis):
        """æ ¹æ®å®é™…æ•°æ®ç¡®å®šåˆ†æé‡ç‚¹"""
        focus_areas = []
        
        # æ ¹æ®æŸ¥è¯¢åˆ†æç¡®å®šåŸºç¡€é‡ç‚¹
        if query_analysis:
            focus_areas.extend(query_analysis.get("analysis_focus", []))
        
        # æ ¹æ®æ•°æ®å†…å®¹è°ƒæ•´é‡ç‚¹
        availability = self._analyze_data_availability(market_info, economic_info, technical_info)
        
        if availability["has_technical_data"]:
            if technical_info.get("data_type") == "trading_signals":
                focus_areas.append("äº¤æ˜“ä¿¡å·åˆ†æ")
                focus_areas.append("æŠ€æœ¯æŒ‡æ ‡ä¸€è‡´æ€§")
            elif technical_info.get("data_type") == "technical_indicators":
                focus_areas.append("æŠ€æœ¯æŒ‡æ ‡æ·±åº¦åˆ†æ")
                focus_areas.append("ä»·æ ¼è¡Œä¸ºåˆ†æ")
        
        if availability["has_economic_data"]:
            if economic_info.get("sentiment", {}).get("overall"):
                focus_areas.append("å¸‚åœºæƒ…ç»ªå½±å“")
            if economic_info.get("events"):
                focus_areas.append("ç»æµäº‹ä»¶åˆ†æ")
            if availability["economic_data_type"] == "multi_currency":
                focus_areas.append("è·¨è´§å¸å¯¹æ¯”è¾ƒåˆ†æ")
        
        if availability["has_market_data"]:
            if availability["market_data_type"] == "real_time":
                focus_areas.append("å®æ—¶ä»·æ ¼åˆ†æ")
            elif availability["market_data_type"] == "historical":
                focus_areas.append("å†å²èµ°åŠ¿åˆ†æ")
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        return list(set(focus_areas))[:5]
    
    def _build_dynamic_analysis_prompt(self, context: Dict[str, Any]) -> str:
        """æ„å»ºåŠ¨æ€åˆ†ææç¤ºï¼Œå¢å¼ºäº¤æ˜“å»ºè®®éƒ¨åˆ†"""
        
        availability = context["data_availability"]
        focus_areas = context["analysis_focus"]
        
        prompt_parts = []
        
        # 1. åˆ†æä»»åŠ¡æè¿°
        prompt_parts.append(f"""# å¤–æ±‡æ·±åº¦åˆ†ææŠ¥å‘Šç”Ÿæˆ

## ç”¨æˆ·æŸ¥è¯¢
{context['user_query'] or "é€šç”¨å¸‚åœºåˆ†æ"}""")

        # 2. æŸ¥è¯¢åˆ†æç»“æœ
        if context['query_analysis']:
            prompt_parts.append(f"""
## æŸ¥è¯¢åˆ†æç»“æœ
- **ä¸»è¦è´§å¸å¯¹**: {context['query_analysis'].get('primary_currency_pair', 'å¾…è¯†åˆ«')}
- **åˆ†æé‡ç‚¹**: {', '.join(focus_areas)}
- **ç”¨æˆ·å…³æ³¨**: {', '.join(context['query_analysis'].get('user_concerns', ['å¸‚åœºèµ°åŠ¿']))}""")

        # 3. æ•°æ®å¯ç”¨æ€§æŠ¥å‘Š
        prompt_parts.append(f"""
## æ•°æ®å¯ç”¨æ€§æŠ¥å‘Š
{self._format_data_availability_report(availability)}""")

        # 4. è¯¦ç»†æ•°æ®å†…å®¹
        prompt_parts.append("""
## è¯¦ç»†æ•°æ®å†…å®¹""")
        
        # æ ¹æ®å®é™…æ•°æ®æ·»åŠ ç›¸åº”éƒ¨åˆ†
        if availability["has_market_data"]:
            prompt_parts.append(f"""
### ğŸ“Š å¸‚åœºæ•°æ®
{self._format_market_data_for_analysis(context['market_data'])}""")
        
        if availability["has_economic_data"]:
            prompt_parts.append(f"""
### ğŸ“ˆ ç»æµæ•°æ®ä¸å¸‚åœºæƒ…ç»ª
{self._format_economic_data_for_analysis(context['economic_data'])}""")
        
        if availability["has_technical_data"]:
            prompt_parts.append(f"""
### ğŸ”§ æŠ€æœ¯åˆ†æ
{self._format_technical_data_for_analysis(context['technical_data'])}""")

        # 5. åˆ†ææŒ‡ä»¤ - å¢å¼ºäº¤æ˜“å»ºè®®éƒ¨åˆ†
        prompt_parts.append(f"""
## åˆ†ææŒ‡ä»¤

è¯·åŸºäºä»¥ä¸Šå®é™…å¯ç”¨çš„æ•°æ®ï¼Œç”Ÿæˆä¸“ä¸šçš„å¤–æ±‡æ·±åº¦åˆ†ææŠ¥å‘Šã€‚**ç‰¹åˆ«å¼ºè°ƒåŸºäºå…·ä½“æ•°æ®ç»™å‡ºå¯æ‰§è¡Œçš„äº¤æ˜“å»ºè®®**ã€‚

### æ ¸å¿ƒåˆ†ææ¡†æ¶

{self._generate_enhanced_analysis_instructions(availability, focus_areas)}

### äº¤æ˜“å»ºè®®å…·ä½“è¦æ±‚

è¯·åŸºäºä»¥ä¸‹å¯ç”¨æ•°æ®ç»™å‡º**å…·ä½“çš„äº¤æ˜“ç­–ç•¥**ï¼š

1. **å…¥åœºæ¡ä»¶**ï¼šåŸºäºæŠ€æœ¯ä¿¡å·ã€ä»·æ ¼æ°´å¹³æˆ–ç»æµäº‹ä»¶çš„å…·ä½“è§¦å‘æ¡ä»¶
2. **ä»“ä½ç®¡ç†**ï¼šæ ¹æ®é£é™©æ°´å¹³å’Œä¿¡å·å¼ºåº¦å»ºè®®ä»“ä½å¤§å°
3. **é£é™©æ§åˆ¶**ï¼šæ˜ç¡®çš„æ­¢æŸä½ç½®å’Œé£é™©ç®¡ç†æªæ–½
4. **ç›®æ ‡ä»·ä½**ï¼šåŸºäºæŠ€æœ¯åˆ†æå’ŒåŸºæœ¬é¢æ”¯æŒçš„å…·ä½“ç›®æ ‡
5. **æ—¶é—´æ¡†æ¶**ï¼šäº¤æ˜“çš„æ—¶é—´å‘¨æœŸå»ºè®®
6. **ç›‘æ§è¦ç‚¹**ï¼šéœ€è¦å…³æ³¨çš„å…³é”®äº‹ä»¶å’Œä»·æ ¼æ°´å¹³

### æŠ¥å‘Šæ ¼å¼è¦æ±‚

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç»„ç»‡æŠ¥å‘Šï¼š

## AI æ·±åº¦åˆ†æ
â”€â”€â”€â”€â”€â”€â”€

### 1. ç»¼åˆå¸‚åœºè¯„ä¼°
[åŸºäºæ‰€æœ‰å¯ç”¨æ•°æ®çš„æ•´ä½“å¸‚åœºåˆ¤æ–­]

### 2. å…³é”®æŠ€æœ¯ä¿¡å·åˆ†æ  
[è¯¦ç»†çš„æŠ€æœ¯æŒ‡æ ‡è§£è¯»å’Œä¿¡å·ä¸€è‡´æ€§]

### 3. åŸºæœ¬é¢é©±åŠ¨å› ç´ 
[ç»æµäº‹ä»¶å’Œæƒ…ç»ªé¢å¯¹ä»·æ ¼çš„å½±å“]

### 4. äº¤æ˜“ç­–ç•¥å»ºè®®
**[è¿™æ˜¯é‡ç‚¹éƒ¨åˆ†ï¼Œå¿…é¡»åŒ…å«å…·ä½“å¯æ‰§è¡Œçš„äº¤æ˜“è®¡åˆ’]**

#### 4.1 ä¸»è¦äº¤æ˜“æœºä¼š
- **æ–¹å‘åå¥½**: æ˜ç¡®çœ‹å¤š/çœ‹ç©º/ä¸­æ€§
- **ç½®ä¿¡æ°´å¹³**: åŸºäºæ•°æ®æ”¯æŒçš„ç¨‹åº¦
- **æ ¸å¿ƒé€»è¾‘**: äº¤æ˜“çš„ä¸»è¦ä¾æ®

#### 4.2 å…·ä½“äº¤æ˜“è®¾ç½®
- **å…¥åœºåŒºåŸŸ**: å…·ä½“ä»·æ ¼åŒºé—´
- **æ­¢æŸä½ç½®**: æ˜ç¡®æ­¢æŸä»·ä½
- **ç›®æ ‡ä»·ä½**: åˆ†æ‰¹ç›®æ ‡ä½ç½®
- **ä»“ä½å»ºè®®**: é£é™©è°ƒæ•´åçš„ä»“ä½å¤§å°

#### 4.3 æ›¿ä»£æ–¹æ¡ˆ
- å¦‚æœä¸»è¦è®¾ç½®æœªè§¦å‘æ—¶çš„å¤‡é€‰è®¡åˆ’

### 5. é£é™©ä¸ç›‘æ§
[å…³é”®é£é™©å› ç´ å’Œéœ€è¦ç›‘æ§çš„äº‹ä»¶]

**é‡è¦**ï¼šæ‰€æœ‰äº¤æ˜“å»ºè®®å¿…é¡»åŸºäºå‰é¢åˆ†æä¸­æåˆ°çš„å…·ä½“æ•°æ®æ”¯æŒï¼Œé¿å…æ³›æ³›è€Œè°ˆã€‚

è¯·å¼€å§‹ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼š""")

        return "\n".join(prompt_parts)
    
    def _generate_enhanced_analysis_instructions(self, availability, focus_areas):
        """ç”Ÿæˆå¢å¼ºçš„åˆ†ææŒ‡ä»¤ï¼Œç‰¹åˆ«å…³æ³¨äº¤æ˜“å»ºè®®"""
        instructions = []
        
        instructions.append("### 1. ç»¼åˆå¸‚åœºè¯„ä¼°")
        
        if availability["has_market_data"]:
            instructions.append("- ğŸ“Š **ä»·æ ¼åˆ†æ**: å½“å‰ä»·æ ¼ã€å˜åŒ–è¶‹åŠ¿ã€å…³é”®æ°´å¹³")
            instructions.append("- ğŸ’° **æ³¢åŠ¨è¯„ä¼°**: åŸºäºä»·æ ¼å˜åŒ–çš„æ³¢åŠ¨æ€§åˆ†æ")
        
        if availability["has_economic_data"]:
            instructions.append("- ğŸ“ˆ **æƒ…ç»ªé¢**: å¸‚åœºæƒ…ç»ªå¾—åˆ†å’Œä¸»è¦ä¸»é¢˜")
            instructions.append("- ğŸ—“ï¸ **äº‹ä»¶é©±åŠ¨**: é‡è¦ç»æµäº‹ä»¶çš„å®é™…å½±å“")
        
        instructions.append("### 2. å…³é”®æŠ€æœ¯ä¿¡å·")
        
        if availability["has_technical_data"]:
            if availability["technical_data_type"] == "trading_signals":
                instructions.append("- ğŸ”” **ç»¼åˆä¿¡å·**: äº¤æ˜“ä¿¡å·å¼ºåº¦å’Œæ–¹å‘")
                instructions.append("- ğŸ“‰ **æŒ‡æ ‡ä¸€è‡´æ€§**: RSIã€MACDç­‰æŒ‡æ ‡ååŒæ€§")
            elif availability["technical_data_type"] == "technical_indicators":
                instructions.append("- ğŸ“Š **æ·±åº¦æŒ‡æ ‡**: å…³é”®æŠ€æœ¯æ°´å¹³åˆ†æ")
                instructions.append("- ğŸ¯ **è¶‹åŠ¿ç¡®è®¤**: è¶‹åŠ¿å¼ºåº¦å’ŒæŒç»­æ€§è¯„ä¼°")
        
        instructions.append("### 3. äº¤æ˜“ç­–ç•¥åˆ¶å®š")
        instructions.append("- ğŸ’¡ **æœºä¼šè¯†åˆ«**: åŸºäºæ•°æ®æ”¯æŒçš„æœ€ä½³äº¤æ˜“æ—¶æœº")
        instructions.append("- âš–ï¸ **é£é™©å›æŠ¥**: å…·ä½“çš„é£é™©å›æŠ¥æ¯”è¯„ä¼°")
        instructions.append("- ğŸ›¡ï¸ **é£æ§æªæ–½**: åŸºäºæ³¢åŠ¨æ€§å’Œæ”¯æ’‘é˜»åŠ›çš„æ­¢æŸè®¾ç½®")
        
        instructions.append("### 4. æ‰§è¡Œä¸ç›‘æ§")
        instructions.append("- ğŸ¯ **å…·ä½“è®¾ç½®**: å…¥åœºã€æ­¢æŸã€ç›®æ ‡çš„æ˜ç¡®ä»·ä½")
        instructions.append("- ğŸ”„ **åŠ¨æ€è°ƒæ•´**: æ ¹æ®å¸‚åœºå˜åŒ–çš„è°ƒæ•´ç­–ç•¥")
        instructions.append("- ğŸ“± **ç›‘æ§è¦ç‚¹**: éœ€è¦é‡ç‚¹å…³æ³¨çš„äº‹ä»¶å’Œæ°´å¹³")
        
        # æ·»åŠ åŸºäºç‰¹å®šæ•°æ®ç±»å‹çš„äº¤æ˜“å»ºè®®é‡ç‚¹
        if availability["has_economic_data"] and availability["economic_data_type"] == "multi_currency":
            instructions.append("\n### ğŸŒ è·¨å¸‚åœºæœºä¼š")
            instructions.append("- åŸºäºå¤šè´§å¸å¯¹åˆ†æçš„ç›¸å¯¹ä»·å€¼æœºä¼š")
        
        if availability["has_technical_data"] and availability["technical_data_type"] == "trading_signals":
            instructions.append("\n### âš¡ ä¿¡å·é©±åŠ¨ç­–ç•¥")
            instructions.append("- åŸºäºå¤åˆäº¤æ˜“ä¿¡å·çš„æ—¶æœºé€‰æ‹©")
        
        return "\n".join(instructions)

    # æ•°æ®æ ¼å¼åŒ–æ–¹æ³• - é’ˆå¯¹åˆ†æä¼˜åŒ–
    def _format_market_data_for_analysis(self, market_data):
        """æ ¼å¼åŒ–å¸‚åœºæ•°æ®ç”¨äºåˆ†æ"""
        if not market_data.get("price"):
            return "æ— æœ‰æ•ˆçš„å¸‚åœºä»·æ ¼æ•°æ®"
        
        lines = []
        price = market_data["price"]
        
        # ä»·æ ¼ä¿¡æ¯
        current_price = price.get('exchange_rate') or price.get('close')
        if current_price:
            lines.append(f"- **å½“å‰ä»·æ ¼**: {current_price}")
        
        if price.get('change') and price.get('percent_change'):
            change_dir = "ğŸ“ˆ" if float(price.get('change', 0)) > 0 else "ğŸ“‰"
            lines.append(f"- **ä»·æ ¼å˜åŒ–**: {change_dir} {price['change']} ({price['percent_change']}%)")
        
        if price.get('volume'):
            lines.append(f"- **äº¤æ˜“é‡**: {price['volume']}")
        
        # è´§å¸å¯¹ä¿¡æ¯
        currency_info = market_data.get("currency_info", {})
        if currency_info.get('pair'):
            lines.append(f"- **åˆ†ææ ‡çš„**: {currency_info['pair']}")
        
        return "\n".join(lines)
    
    def _format_economic_data_for_analysis(self, economic_data):
        """æ ¼å¼åŒ–ç»æµæ•°æ®ç”¨äºåˆ†æ - å¢å¼ºäº¤æ˜“ç›¸å…³ä¿¡æ¯"""
        if not economic_data:
            return "æ— ç»æµæ•°æ®å¯ç”¨"
        
        lines = []
        
        # å¸‚åœºæƒ…ç»ª
        sentiment = economic_data.get("sentiment", {})
        if sentiment.get("overall"):
            sentiment_emoji = "ğŸ‚" if "æ¶¨" in sentiment["overall"] else "ğŸ»" if "è·Œ" in sentiment["overall"] else "âš–ï¸"
            lines.append(f"- **å¸‚åœºæƒ…ç»ª**: {sentiment_emoji} {sentiment['overall']}")
            if sentiment.get("score"):
                confidence = "é«˜" if sentiment['score'] > 70 else "ä½" if sentiment['score'] < 30 else "ä¸­"
                lines.append(f"- **æƒ…ç»ªå¼ºåº¦**: {sentiment['score']}/100 ({confidence}ç½®ä¿¡åº¦)")
        
        # å…³é”®ä¸»é¢˜
        key_themes = sentiment.get("key_themes", [])
        if key_themes:
            lines.append(f"- **å¸‚åœºä¸»é¢˜**: {', '.join(key_themes[:3])}")
        
        # ç»æµäº‹ä»¶ - é‡ç‚¹å…³æ³¨é«˜å½±å“äº‹ä»¶
        events = economic_data.get("events", [])
        high_impact_events = [e for e in events if e.get("importance") == "é«˜"]
        
        if high_impact_events:
            lines.append(f"- **é«˜å½±å“äº‹ä»¶**: {len(high_impact_events)}ä¸ªå¾…å…³æ³¨")
            for event in high_impact_events[:3]:  # æ˜¾ç¤ºæœ€é‡è¦çš„3ä¸ªäº‹ä»¶
                status_emoji = "ğŸŸ¢" if event.get("status") == "å·²å‘å¸ƒ" else "ğŸŸ¡" if event.get("status") == "è¿›è¡Œä¸­" else "ğŸ”´"
                actual_info = f"å®é™…å€¼: {event.get('actual')}" if event.get('actual') else "å¾…å‘å¸ƒ"
                lines.append(f"  - {status_emoji} {event.get('name')}: {actual_info}")
        
        # äº¤æ˜“å»ºè®® - å¢å¼ºæ˜¾ç¤º
        recommendation = economic_data.get("recommendation", {})
        if recommendation.get("bias"):
            bias_emoji = "ğŸŸ¢" if "å¤š" in recommendation["bias"] else "ğŸ”´" if "ç©º" in recommendation["bias"] else "ğŸŸ¡"
            lines.append(f"- **å·¥å…·å»ºè®®**: {bias_emoji} {recommendation['bias']}")
            if recommendation.get("confidence"):
                lines.append(f"- **å»ºè®®ç½®ä¿¡åº¦**: {recommendation['confidence']}")
        
        # é£é™©å› ç´ 
        risk_factors = recommendation.get("risk_factors", [])
        if risk_factors:
            lines.append(f"- **ä¸»è¦é£é™©**: {', '.join(risk_factors[:2])}")
        
        return "\n".join(lines) if lines else "ç»æµæ•°æ®å†…å®¹æœ‰é™"

    def _format_technical_data_for_analysis(self, technical_data):
        """æ ¼å¼åŒ–æŠ€æœ¯æ•°æ®ç”¨äºåˆ†æ - å¢å¼ºäº¤æ˜“ä¿¡å·ä¿¡æ¯"""
        if not technical_data:
            return "æ— æŠ€æœ¯åˆ†ææ•°æ®"
        
        lines = []
        
        data_type = technical_data.get("data_type")
        lines.append(f"- **æ•°æ®ç±»å‹**: {data_type}")
        
        if data_type == "trading_signals":
            # äº¤æ˜“ä¿¡å·æ ¼å¼ - å¢å¼ºæ˜¾ç¤º
            composite = technical_data.get("composite_signal", {})
            if composite.get("recommendation"):
                signal_emoji = "ğŸŸ¢" if "å¤š" in composite["recommendation"] else "ğŸ”´" if "ç©º" in composite["recommendation"] else "ğŸŸ¡"
                lines.append(f"- **ç»¼åˆä¿¡å·**: {signal_emoji} {composite['recommendation']}")
                if composite.get("confidence"):
                    conf_level = "å¼º" if composite['confidence'] > 70 else "å¼±" if composite['confidence'] < 30 else "ä¸­"
                    lines.append(f"- **ä¿¡å·å¼ºåº¦**: {composite['confidence']}% ({conf_level})")
            
            # å¤šç©ºä¿¡å·å¯¹æ¯”
            bullish_count = composite.get("bullish_count", 0)
            bearish_count = composite.get("bearish_count", 0)
            lines.append(f"- **å¤šç©ºå¯¹æ¯”**: {bullish_count}ä¸ªçœ‹æ¶¨ vs {bearish_count}ä¸ªçœ‹è·Œ")
            
            # è¯¦ç»†æŒ‡æ ‡ä¿¡å·
            signals = technical_data.get("signals", {})
            indicator_lines = []
            
            if signals.get("rsi"):
                rsi_val = signals["rsi"].get("value")
                if rsi_val:
                    rsi_status = "è¶…å–" if rsi_val < 30 else "è¶…ä¹°" if rsi_val > 70 else "ä¸­æ€§"
                    indicator_lines.append(f"RSI({rsi_val}-{rsi_status})")
            
            if signals.get("macd"):
                macd_signal = signals["macd"].get("signal", "")
                if macd_signal:
                    indicator_lines.append(f"MACD({macd_signal})")
            
            if signals.get("trend"):
                trend_strength = signals["trend"].get("strength", "")
                if trend_strength:
                    indicator_lines.append(f"è¶‹åŠ¿({trend_strength})")
            
            if indicator_lines:
                lines.append(f"- **å…³é”®æŒ‡æ ‡**: {', '.join(indicator_lines)}")
                
        elif data_type == "technical_indicators":
            # æŠ€æœ¯æŒ‡æ ‡æ ¼å¼ - å¢å¼ºæ˜¾ç¤º
            indicators = technical_data.get("indicators", {})
            indicator_lines = []
            
            if indicators.get("RSI"):
                rsi_val = indicators["RSI"]
                rsi_status = "è¶…å–" if rsi_val < 30 else "è¶…ä¹°" if rsi_val > 70 else "ä¸­æ€§"
                indicator_lines.append(f"RSI({rsi_val}-{rsi_status})")
            
            if indicators.get("MACD"):
                macd_val = indicators["MACD"]
                macd_signal = "çœ‹æ¶¨" if macd_val > 0 else "çœ‹è·Œ"
                indicator_lines.append(f"MACD({macd_val}-{macd_signal})")
            
            if indicators.get("BB_Position"):
                bb_pos = indicators["BB_Position"]
                bb_status = "ä¸Šè½¨" if bb_pos > 0.7 else "ä¸‹è½¨" if bb_pos < 0.3 else "ä¸­è½¨"
                indicator_lines.append(f"å¸ƒæ—å¸¦({bb_status})")
            
            if indicator_lines:
                lines.append(f"- **æŠ€æœ¯æŒ‡æ ‡**: {', '.join(indicator_lines)}")
            
            # ä»·æ ¼æ‘˜è¦
            price_info = technical_data.get("price", {})
            if price_info.get("current"):
                change_emoji = "ğŸ“ˆ" if price_info.get("change_pct", 0) > 0 else "ğŸ“‰"
                lines.append(f"- **å½“å‰ä»·æ ¼**: {price_info['current']} {change_emoji}")
        
        return "\n".join(lines) if lines else "æŠ€æœ¯æ•°æ®å†…å®¹æœ‰é™"

    # ä¿ç•™åŸæœ‰çš„æ•°æ®æå–æ–¹æ³•ï¼ˆä¸éœ€è¦ä¿®æ”¹ï¼‰
    def _extract_market_data(self, market_data):
        """æå–å¸‚åœºæ•°æ® - é€‚é…data_fetcherçš„å®é™…æ ¼å¼"""
        # ä¿æŒåŸæœ‰å®ç°ä¸å˜
        key_data = {}
        
        if not market_data or not market_data.get("success"):
            return key_data
        
        try:
            data_content = market_data.get("data", {})
            
            # å¤„ç†å®æ—¶æ•°æ®ï¼ˆå•ä¸ªå­—å…¸ï¼‰
            if isinstance(data_content, dict) and data_content:
                key_data["price"] = {
                    "exchange_rate": data_content.get("exchange_rate"),
                    "open": data_content.get("open"),
                    "high": data_content.get("high"),
                    "low": data_content.get("low"), 
                    "close": data_content.get("exchange_rate"),
                    "volume": data_content.get("volume"),
                    "change": data_content.get("change"),
                    "percent_change": data_content.get("percent_change")
                }
                key_data["currency_info"] = {
                    "from_currency": data_content.get("from_currency"),
                    "to_currency": data_content.get("to_currency"),
                    "pair": market_data.get("currency_pair")
                }
                key_data["metadata"] = {
                    "data_type": "real_time",
                    "success": market_data.get("success"),
                    "source": "data_fetcher"
                }
            
            # å¤„ç†å†å²/æ—¥å†…æ•°æ®ï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰
            elif isinstance(data_content, list) and len(data_content) > 0:
                latest = data_content[-1]
                key_data["price"] = {
                    "open": latest.get("open"),
                    "high": latest.get("high"),
                    "low": latest.get("low"),
                    "close": latest.get("close"),
                    "volume": latest.get("volume"),
                    "datetime": latest.get("datetime")
                }
                key_data["summary"] = market_data.get("summary", {})
                key_data["metadata"] = {
                    "data_type": "historical",
                    "success": market_data.get("success"),
                    "source": "data_fetcher"
                }
            
        except Exception as e:
            logger.error(f"æå–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            key_data["error"] = f"æ•°æ®æå–é”™è¯¯: {str(e)}"
        
        return key_data

    def _extract_economic_data(self, economic_data):
        """æå–ç»æµæ•°æ® - é€‚é…economic_calendarçš„å®é™…å¤æ‚æ ¼å¼"""
        # ä¿æŒåŸæœ‰å®ç°ä¸å˜
        extracted = {}
        
        if not economic_data or not economic_data.get("success"):
            return extracted
        
        try:
            # å¤„ç†å¤šè´§å¸å¯¹åˆ†æç»“æœ
            if economic_data.get("analysis_type") == "multi_currency":
                extracted["analysis_type"] = "multi_currency"
                extracted["currency_pairs"] = economic_data.get("currency_pairs_analyzed", [])
                extracted["summary"] = economic_data.get("summary", {})
                # å–ç¬¬ä¸€ä¸ªè´§å¸å¯¹çš„è¯¦ç»†åˆ†æä½œä¸ºä»£è¡¨
                individual_analyses = economic_data.get("individual_analyses", {})
                if individual_analyses:
                    first_pair = list(individual_analyses.keys())[0]
                    representative_data = individual_analyses[first_pair]
                    if representative_data.get("success"):
                        extracted.update(self._extract_single_currency_economic_data(representative_data))
            else:
                # å•è´§å¸å¯¹åˆ†æ
                extracted.update(self._extract_single_currency_economic_data(economic_data))
            
        except Exception as e:
            logger.error(f"æå–ç»æµæ•°æ®å¤±è´¥: {e}")
            extracted["error"] = str(e)
        
        return extracted

    def _extract_single_currency_economic_data(self, economic_data):
        """æå–å•è´§å¸å¯¹ç»æµæ•°æ®"""
        # ä¿æŒåŸæœ‰å®ç°ä¸å˜
        extracted = {}
        
        try:
            # æå–å¸‚åœºæƒ…ç»ª
            market_context = economic_data.get("market_context", {})
            extracted["sentiment"] = {
                "overall": market_context.get("overall_sentiment"),
                "score": market_context.get("sentiment_score"),
                "key_themes": market_context.get("key_market_themes", []),
                "volatility": market_context.get("volatility_outlook")
            }
            
            # æå–ç»æµäº‹ä»¶
            calendar_analysis = economic_data.get("economic_calendar_analysis", {})
            extracted["events"] = [
                {
                    "name": e.get("event_name"),
                    "date": e.get("event_date"),
                    "importance": e.get("importance_level"),
                    "actual": e.get("actual_value"),
                    "status": e.get("status")
                }
                for e in calendar_analysis.get("events", [])
            ]
            
            extracted["event_summary"] = {
                "total_events": calendar_analysis.get("total_events", 0),
                "high_impact_events": calendar_analysis.get("high_impact_events", 0),
                "period_covered": calendar_analysis.get("period_covered", "")
            }
            
            # æå–äº¤æ˜“å»ºè®®
            trading_rec = economic_data.get("trading_recommendation", {})
            extracted["recommendation"] = {
                "bias": trading_rec.get("overall_bias"),
                "confidence": trading_rec.get("confidence_level"),
                "risk_factors": trading_rec.get("key_risk_factors", []),
                "actions": trading_rec.get("recommended_actions", [])
            }
            
        except Exception as e:
            logger.error(f"æå–å•è´§å¸ç»æµæ•°æ®å¤±è´¥: {e}")
            extracted["error"] = str(e)
        
        return extracted

    def _extract_technical_data(self, technical_data):
        """æå–æŠ€æœ¯åˆ†ææ•°æ® - é€‚é…technical_analyzerçš„å®é™…æ ¼å¼"""
        # ä¿æŒåŸæœ‰å®ç°ä¸å˜
        extracted = {}
        
        if not technical_data or not technical_data.get("success"):
            return extracted
        
        try:
            # åˆ¤æ–­æ•°æ®æ¥æºï¼šcalculate_indicators è¿˜æ˜¯ generate_signals
            data_type = self._detect_technical_data_type(technical_data)
            
            if data_type == "indicators":
                extracted["data_type"] = "technical_indicators"
                extracted["symbol"] = technical_data.get("symbol")
                extracted["record_count"] = technical_data.get("record_count", 0)
                
                # æå–ä»·æ ¼æ‘˜è¦
                price_summary = technical_data.get("price_summary", {})
                extracted["price"] = {
                    "current": price_summary.get("current_price"),
                    "change": price_summary.get("price_change"),
                    "change_pct": price_summary.get("price_change_pct")
                }
                
                # æå–æŠ€æœ¯æŒ‡æ ‡æ•°æ®
                data_list = technical_data.get("data", [])
                if data_list:
                    latest_data = data_list[-1]
                    extracted["indicators"] = self._extract_indicators_from_data(latest_data)
                
                extracted["available_indicators"] = technical_data.get("indicators_calculated", [])
                
            elif data_type == "signals":
                extracted["data_type"] = "trading_signals"
                extracted["symbol"] = technical_data.get("symbol")
                extracted["timestamp"] = technical_data.get("timestamp")
                extracted["price"] = technical_data.get("price")
                
                # æå–å„ä¸ªæŠ€æœ¯ä¿¡å·
                extracted["signals"] = {
                    "rsi": technical_data.get("rsi", {}),
                    "macd": technical_data.get("macd", {}),
                    "bollinger_bands": technical_data.get("bollinger_bands", {}),
                    "stochastic": technical_data.get("stochastic", {}),
                    "moving_averages": technical_data.get("moving_averages", {}),
                    "trend": technical_data.get("trend", {}),
                    "volatility": technical_data.get("volatility", {})
                }
                
                # æå–ç»¼åˆä¿¡å·
                composite_signal = technical_data.get("composite_signal", {})
                extracted["composite_signal"] = {
                    "recommendation": composite_signal.get("recommendation"),
                    "confidence": composite_signal.get("confidence"),
                    "bullish_count": composite_signal.get("bullish_signals"),
                    "bearish_count": composite_signal.get("bearish_signals")
                }
                
            extracted["metadata"] = {
                "success": technical_data.get("success", False),
                "data_type": data_type,
                "source": "technical_analyzer"
            }
            
        except Exception as e:
            logger.error(f"æå–æŠ€æœ¯æ•°æ®å¤±è´¥: {e}")
            extracted["error"] = str(e)
        
        return extracted

    def _detect_technical_data_type(self, data):
        """æ£€æµ‹æŠ€æœ¯æ•°æ®çš„ç±»å‹"""
        if "composite_signal" in data:
            return "signals"
        elif "data" in data and "indicators_calculated" in data:
            return "indicators"
        else:
            return "unknown"

    def _extract_indicators_from_data(self, data_point):
        """ä»æ•°æ®ç‚¹ä¸­æå–æŠ€æœ¯æŒ‡æ ‡"""
        indicators = {}
        
        indicator_fields = [
            'RSI', 'MACD', 'MACD_Signal', 'MACD_Histogram',
            'Stoch_K', 'Stoch_D', 'BB_Upper', 'BB_Middle', 
            'BB_Lower', 'BB_Width', 'BB_Position', 'ATR'
        ]
        
        for i in [5, 10, 20, 50, 200]:
            indicator_fields.append(f'EMA_{i}')
        
        for field in indicator_fields:
            if field in data_point:
                value = data_point[field]
                if value is None or (isinstance(value, float) and np.isnan(value)):
                    indicators[field] = None
                else:
                    indicators[field] = value
        
        return indicators

    




    def _get_timestamp(self) -> str:
        """è·å–æ—¶é—´æˆ³"""
        return datetime.now().isoformat()


    def react_reasoning(self, question: str, available_tools: list = None, context: str = None) -> Dict[str, Any]:
        """
        ReActæ¨ç† - åˆ†æé—®é¢˜å¹¶åˆ¶å®šè°ƒæŸ¥è®¡åˆ’
        """
        if not self.client:
            return {
                "success": False,
                "error": "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®",
                "reasoning_plan": None
            }
        
        try:
            prompt = f"""
    ä½œä¸ºå¤–æ±‡äº¤æ˜“åˆ†æå¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹é—®é¢˜å¹¶åˆ¶å®šè°ƒæŸ¥è®¡åˆ’ï¼š

    é—®é¢˜: {question}
    å¯ç”¨å·¥å…·: {available_tools or ['data_fetcher', 'technical_analyzer', 'economic_calendar']}
    ä¸Šä¸‹æ–‡: {context or 'æ— '}

    è¯·åˆ†æï¼š
    1. **ç¡®å®šç›®æ ‡è´§å¸å¯¹**ï¼šä»é—®é¢˜ä¸­è¯†åˆ«å‡ºä¸»è¦çš„åˆ†æè´§å¸å¯¹ï¼ˆä¾‹å¦‚ EUR/USD, GBP/JPYï¼‰ã€‚å¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å‡ºï¼Œåˆ™å°è¯•æ¨æ–­æœ€ç›¸å…³çš„è´§å¸å¯¹ã€‚
    2. è¿™ä¸ªé—®é¢˜éœ€è¦å“ªäº›ç±»å‹çš„æ•°æ®ï¼Ÿï¼ˆç»æµæ•°æ®ã€æ–°é—»ã€æŠ€æœ¯åˆ†æç­‰ï¼‰
    3. åº”è¯¥æŒ‰ä»€ä¹ˆé¡ºåºæ”¶é›†è¿™äº›æ•°æ®ï¼Ÿ
    4. å“ªäº›æ˜¯å…³é”®å› ç´ éœ€è¦é‡ç‚¹å…³æ³¨ï¼Ÿ

    è¯·ä»¥JSONæ ¼å¼è¿”å›æ¨ç†è®¡åˆ’ï¼š
    {{
        "reasoning": "æ€è€ƒè¿‡ç¨‹æè¿°",
        "target_currency_pair": "è¯†åˆ«å‡ºçš„ç›®æ ‡è´§å¸å¯¹ï¼Œä¾‹å¦‚ EUR/USD æˆ– N/A",
        "need_economic_data": true/false,
        "need_technical_analysis": true/false,
        "need_market_data": true/false,
        "need_news_analysis": true/false,
        "investigation_steps": ["æ­¥éª¤1", "æ­¥éª¤2", "æ­¥éª¤3"],
        "key_factors": ["å› ç´ 1", "å› ç´ 2"],
        "expected_data_sources": ["source1", "source2"]
    }}
    """
            response = self.client.chat.completions.create(
                model=self.default_model,
                messages=[
                    {"role": "system", "content": "æ‚¨æ˜¯ä¸“ä¸šçš„å¤–æ±‡å¸‚åœºåˆ†æå¸ˆï¼Œæ“…é•¿åˆ¶å®šè°ƒæŸ¥è®¡åˆ’ï¼Œè¯·åŠ¡å¿…ä»é—®é¢˜ä¸­è¯†åˆ«ç›®æ ‡è´§å¸å¯¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            reasoning_plan = json.loads(response.choices[0].message.content)

            # è´§å¸å¯¹æ ¼å¼å¤„ç†
            pair = reasoning_plan.get("target_currency_pair")
            if pair and isinstance(pair, str) and pair.upper() != "N/A":
                # ç®€åŒ–å¤„ç†ï¼šä¿æŒåŸå§‹æ ¼å¼ï¼Œè®©è°ƒç”¨æ–¹å¤„ç†
                reasoning_plan["target_currency_pair"] = pair.upper().replace(" ", "")
            
            return {
                "success": True,
                "reasoning_plan": reasoning_plan,
                "query": question,
                "timestamp": self._get_timestamp()
            }
            
        except Exception as e:
            logger.error(f"ReActæ¨ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"æ¨ç†è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}",
                "reasoning_plan": None
            }
        

    def evaluate_evidence(self, question: str, current_findings: Dict[str, Any], 
                        collected_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ä¸­æœŸæ¨ç† - è¯„ä¼°å·²æ”¶é›†è¯æ®å¹¶å†³å®šä¸‹ä¸€æ­¥
        """
        if not self.client:
            return {
                "success": False,
                "error": "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–",
                "evaluation": None
            }
        
        try:
            prompt = f"""
    åŸºäºå·²æ”¶é›†çš„è¯æ®ï¼Œè¯„ä¼°åˆ†æè¿›å±•ï¼š

    åŸå§‹é—®é¢˜: {question}
    å½“å‰æ¨ç†è®¡åˆ’: {json.dumps(current_findings, ensure_ascii=False, indent=2)}

    å·²æ”¶é›†æ•°æ®:
    {json.dumps(collected_data or {}, ensure_ascii=False, indent=2)}

    è¯·è¯„ä¼°ï¼š
    1. å½“å‰è¯æ®æ˜¯å¦è¶³å¤Ÿå›ç­”åŸé—®é¢˜ï¼Ÿ
    2. è¿˜éœ€è¦å“ªäº›é¢å¤–ä¿¡æ¯ï¼Ÿ
    3. å‘ç°äº†å“ªäº›å…³é”®çº¿ç´¢ï¼Ÿ
    4. å»ºè®®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨æ˜¯ä»€ä¹ˆï¼Ÿ

    è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼š
    {{
        "reasoning": "è¯„ä¼°æ€è€ƒè¿‡ç¨‹",
        "evidence_sufficient": true/false,
        "need_more_data": true/false,
        "missing_information": ["ä¿¡æ¯1", "ä¿¡æ¯2"],
        "key_insights": ["å‘ç°1", "å‘ç°2"],
        "next_steps": ["ä¸‹ä¸€æ­¥1", "ä¸‹ä¸€æ­¥2"],
        "confidence_level": "é«˜/ä¸­/ä½"
    }}
    """
            
            response = self.client.chat.completions.create(
                model=self.default_model,
                messages=[
                    {"role": "system", "content": "æ‚¨æ˜¯ä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿è¯„ä¼°è¯æ®å®Œæ•´æ€§ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            evaluation = json.loads(response.choices[0].message.content)
            
            return {
                "success": True,
                "evaluation": evaluation,
                "question": question,
                "timestamp": self._get_timestamp()
            }
            
        except Exception as e:
            logger.error(f"è¯æ®è¯„ä¼°å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"è¯æ®è¯„ä¼°å¤±è´¥: {str(e)}",
                "evaluation": None
            }

    def react_final_analysis(self, question: str, reasoning_steps: Dict[str, Any],
                            all_collected_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ReActæœ€ç»ˆåˆ†æ - åŸºäºæ¨ç†è¿‡ç¨‹å’Œæ•°æ®ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        """
        if not self.client:
            return {
                "success": False,
                "error": "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–",
                "final_analysis": None
            }
        
        try:
            prompt = f"""
    åŸºäºå®Œæ•´çš„ReActæ¨ç†è¿‡ç¨‹å’Œæ•°æ®æ”¶é›†ï¼Œè¯·ç»™å‡ºæœ€ç»ˆåˆ†æï¼š

    åŸå§‹é—®é¢˜: {question}

    æ¨ç†è¿‡ç¨‹è®°å½•:
    {json.dumps(reasoning_steps, ensure_ascii=False, indent=2)}

    æ‰€æœ‰æ”¶é›†çš„æ•°æ®:
    {json.dumps(all_collected_data, ensure_ascii=False, indent=2)}

    è¯·è¿›è¡Œç»¼åˆæ¨ç†åˆ†æï¼š
    1. æ€»ç»“æ•´ä¸ªè°ƒæŸ¥è¿‡ç¨‹
    2. åŸºäºæ‰€æœ‰è¯æ®ç»™å‡ºæ˜ç¡®ç­”æ¡ˆ
    3. æä¾›æ•°æ®æ”¯æŒçš„å…³é”®å‘ç°
    4. ç»™å‡ºä¸“ä¸šç»“è®ºå’Œå»ºè®®

    è¯·ä»¥JSONæ ¼å¼è¿”å›æœ€ç»ˆåˆ†æï¼š
    {{
        "reasoning_process_summary": "æ¨ç†è¿‡ç¨‹æ€»ç»“",
        "key_findings": ["å‘ç°1", "å‘ç°2"],
        "primary_causes": ["åŸå› 1", "åŸå› 2"],
        "supporting_evidence": {{
            "evidence1": "æ•°æ®æ”¯æŒ1",
            "evidence2": "æ•°æ®æ”¯æŒ2"
        }},
        "confidence_level": "é«˜/ä¸­/ä½",
        "final_conclusion": "æœ€ç»ˆç»“è®º",
        "recommendations": ["å»ºè®®1", "å»ºè®®2"],
        "limitations": ["é™åˆ¶1", "é™åˆ¶2"]
    }}
    """
            
            response = self.client.chat.completions.create(
                model=self.default_model,
                messages=[
                    {"role": "system", "content": "æ‚¨æ˜¯é¡¶çº§å¤–æ±‡åˆ†æå¸ˆï¼Œæ“…é•¿åŸºäºæ¨ç†è¿‡ç¨‹å’Œæ•°æ®ç»™å‡ºä¸“ä¸šç»“è®ºã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            final_analysis = json.loads(response.choices[0].message.content)
            
            return {
                "success": True,
                "final_analysis": final_analysis,
                "reasoning_steps_used": len(reasoning_steps),
                "data_sources_used": list(all_collected_data.keys()),
                "timestamp": self._get_timestamp()
            }
            
        except Exception as e:
            logger.error(f"æœ€ç»ˆåˆ†æå¤±è´¥: {e}")
            
            return {
                "success": False,
                "error": f"æœ€ç»ˆåˆ†æå¤±è´¥: {str(e)}",
                "final_analysis": None
            }
        
    def quick_analysis(self, data: Dict[str, Any], analysis_type: str = "general") -> Dict[str, Any]:
        """å¿«é€Ÿåˆ†æå•ä¸ªæ•°æ®æº"""
        if not self.client:
            return {"success": False, "error": "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–"}
        
        try:
            prompt = f"è¯·å¯¹ä»¥ä¸‹{analysis_type}æ•°æ®è¿›è¡Œåˆ†æ: {json.dumps(data, ensure_ascii=False)}"
            
            response = self.client.chat.completions.create(
                model=self.default_model,
                messages=[
                    {"role": "system", "content": "æ‚¨æ˜¯æ•°æ®åˆ†æä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            
            return {
                "success": True,
                "analysis": response.choices[0].message.content,
                "type": analysis_type
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        status = "healthy" if self.client else "degraded"
        ai_status = "available" if self.client else "unavailable"
        
        return {
            "status": status,
            "service": "analyzer",
            "ai_capabilities": ai_status,
            "default_model": self.default_model,
            "openai_configured": bool(self.openai_api_key),
            "base_url_configured": bool(self.openai_base_url),
            "timestamp": self._get_timestamp()
        }
